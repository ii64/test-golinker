// +build !noasm !appengine
// Code generated by golinker, DO NOT EDIT.
// Command: golinker -fallback-rawbytes-x86 -rawbytes-x86 -extsymstub -stub=./internal/native/stub.go -out=./internal/native -entryname=__native_entry__ ./native/libnative-amd64.a

#include "go_asm.h"
#include "funcdata.h"
#include "textflag.h"

// native size: 1247

TEXT Â·__native_entry__(SB), NOSPLIT, $0
	NO_LOCAL_POINTERS

__subr_native_entry__off_0:
	LONG $0xf9058d48; WORD $0xffff; BYTE $0xff	// leaq -7(%rip), %rax	// LEAQ -0x7(RIP), AX

_lbl_7:
	LONG $0x24448948; BYTE $0x10	// movq %rax, 0x10(%rsp)	// MOVQ AX, 0x10(SP)
	BYTE $0xc3	// retq	// RET 

__subr_____native_entry___aligner16_3__13__off_13:
	WORD $0x1f0f; BYTE $0x0	// nopl (%rax)	// NOPL (AX)

__subr_subr__off_16:
	BYTE $0x55	// pushq %rbp	// PUSHQ BP
	WORD $0x8948; BYTE $0xe5	// movq %rsp, %rbp	// MOVQ SP, BP
	LONG $0xfebabeb8; BYTE $0xca	// movl $0xcafebabe, %eax	// MOVL $0xcafebabe, AX
	BYTE $0x5d	// popq %rbp	// POPQ BP
	BYTE $0xc3	// retq	// RET 
	LONG $0x441f0f; BYTE $0x0	// nopl (%rax, %rax)	// NOPL (AX)(AX*1)

__subr_subr2__off_32:
	WORD $0x8548; BYTE $0xff	// testq %rdi, %rdi	// TESTQ DI, DI
	WORD $0x4374	// je 0x68	// JE _lbl_68
	BYTE $0x55	// pushq %rbp	// PUSHQ BP
	WORD $0x8948; BYTE $0xe5	// movq %rsp, %rbp	// MOVQ SP, BP
	LONG $0x8478b48	// movq 8(%rdi), %rax	// MOVQ 0x8(DI), AX
	WORD $0x8548; BYTE $0xc0	// testq %rax, %rax	// TESTQ AX, AX

_lbl_30:
	WORD $0x347e	// jle 0x66	// JLE _lbl_66
	WORD $0x8b48; BYTE $0xf	// movq (%rdi), %rcx	// MOVQ (DI), CX
	WORD $0xd231	// xorl %edx, %edx	// XORL DX, DX
	LONG $0xa6358d48; WORD $0x4; BYTE $0x0	// leaq 0x4a6(%rip), %rsi	// LEAQ 0x4a6(RIP), SI
	WORD $0x9066	// nop	// NOP 

_lbl_40:
	WORD $0xd089	// movl %edx, %eax	// MOVL DX, AX
	LONG $0x4fc06948; WORD $0xc4ec; BYTE $0x4e	// imulq $0x4ec4ec4f, %rax, %rax	// IMULQ $0x4ec4ec4f, AX, AX
	LONG $0x22e8c148	// shrq $0x22, %rax	// SHRQ $0x22, AX
	WORD $0xc06b; BYTE $0xf3	// imull $-0xd, %eax, %eax	// IMULL $-0xd, AX, AX
	WORD $0xd001	// addl %edx, %eax	// ADDL DX, AX
	LONG $0x3004b60f	// movzbl (%rax, %rsi), %eax	// 
	WORD $0x488; BYTE $0x11	// movb %al, (%rcx, %rdx)	// MOVB AX, (CX)(DX*1)
	LONG $0x1c28348	// addq $1, %rdx	// ADDQ $0x1, DX
	LONG $0x8478b48	// movq 8(%rdi), %rax	// MOVQ 0x8(DI), AX
	WORD $0x3948; BYTE $0xd0	// cmpq %rdx, %rax	// CMPQ AX, DX
	WORD $0xda7f	// jg 0x40	// JG _lbl_40

_lbl_66:
	BYTE $0x5d	// popq %rbp	// POPQ BP
	BYTE $0xc3	// retq	// RET 

_lbl_68:
	LONG $0xffffffb8; BYTE $0xff	// movl $0xffffffff, %eax	// MOVL $0xffffffff, AX
	BYTE $0xc3	// retq	// RET 
	WORD $0x9066	// nop	// NOP 

__subr_subr3__off_112:
	BYTE $0x55	// pushq %rbp	// PUSHQ BP
	WORD $0x8948; BYTE $0xe5	// movq %rsp, %rbp	// MOVQ SP, BP
	WORD $0xc031	// xorl %eax, %eax	// XORL AX, AX
	WORD $0x8548; BYTE $0xff	// testq %rdi, %rdi	// TESTQ DI, DI
	WORD $0x4b74	// je 0xc6	// JE _lbl_c6
	WORD $0x8b48; BYTE $0xf	// movq (%rdi), %rcx	// MOVQ (DI), CX
	WORD $0x8548; BYTE $0xc9	// testq %rcx, %rcx	// TESTQ CX, CX
	WORD $0x4374	// je 0xc6	// JE _lbl_c6
	LONG $0x8478b48	// movq 8(%rdi), %rax	// MOVQ 0x8(DI), AX
	WORD $0x8548; BYTE $0xc0	// testq %rax, %rax	// TESTQ AX, AX
	WORD $0x3a7e	// jle 0xc6	// JLE _lbl_c6
	WORD $0xd231	// xorl %edx, %edx	// XORL DX, DX
	LONG $0x4f358d48; WORD $0x4; BYTE $0x0	// leaq 0x44f(%rip), %rsi	// LEAQ 0x44f(RIP), SI
	QUAD $0x841f0f2e66; WORD $0x0	// nopw %cs:(%rax, %rax)	// NOPW (CS)(AX*1)
	BYTE $0x90	// nop	// NOP 

_lbl_a0:
	WORD $0xd089	// movl %edx, %eax	// MOVL DX, AX
	LONG $0x4fc06948; WORD $0xc4ec; BYTE $0x4e	// imulq $0x4ec4ec4f, %rax, %rax	// IMULQ $0x4ec4ec4f, AX, AX
	LONG $0x22e8c148	// shrq $0x22, %rax	// SHRQ $0x22, AX
	WORD $0xc06b; BYTE $0xf3	// imull $-0xd, %eax, %eax	// IMULL $-0xd, AX, AX
	WORD $0xd001	// addl %edx, %eax	// ADDL DX, AX
	LONG $0x3004b60f	// movzbl (%rax, %rsi), %eax	// 
	WORD $0x488; BYTE $0x11	// movb %al, (%rcx, %rdx)	// MOVB AX, (CX)(DX*1)
	LONG $0x1c28348	// addq $1, %rdx	// ADDQ $0x1, DX
	LONG $0x8478b48	// movq 8(%rdi), %rax	// MOVQ 0x8(DI), AX
	WORD $0x3948; BYTE $0xd0	// cmpq %rdx, %rax	// CMPQ AX, DX
	WORD $0xda7f	// jg 0xa0	// JG _lbl_a0

_lbl_c6:
	BYTE $0x5d	// popq %rbp	// POPQ BP
	BYTE $0xc3	// retq	// RET 
	QUAD $0x841f0f	// nopl (%rax, %rax)	// NOPL (AX)(AX*1)

__subr_subrSimd__off_208:
	BYTE $0x55	// pushq %rbp	// PUSHQ BP
	WORD $0x8948; BYTE $0xe5	// movq %rsp, %rbp	// MOVQ SP, BP
	WORD $0x5641	// pushq %r14	// PUSHQ R14
	BYTE $0x53	// pushq %rbx	// PUSHQ BX
	WORD $0xc031	// xorl %eax, %eax	// XORL AX, AX
	WORD $0x8548; BYTE $0xff	// testq %rdi, %rdi	// TESTQ DI, DI
	LONG $0x3f0840f; WORD $0x0	// je 0x4d2	// JE _lbl_4d2
	WORD $0x8b48; BYTE $0xf	// movq (%rdi), %rcx	// MOVQ (DI), CX
	WORD $0x8548; BYTE $0xc9	// testq %rcx, %rcx	// TESTQ CX, CX
	LONG $0x3e4840f; WORD $0x0	// je 0x4d2	// JE _lbl_4d2
	LONG $0x8578b48	// movq 8(%rdi), %rdx	// MOVQ 0x8(DI), DX
	WORD $0xd285	// testl %edx, %edx	// TESTL DX, DX
	LONG $0x3d88e0f; WORD $0x0	// jle 0x4d2	// JLE _lbl_4d2
	WORD $0xfa83; BYTE $0x10	// cmpl $0x10, %edx	// CMPL DX, $0x10
	LONG $0x7c820f; WORD $0x0	// jb 0x17f	// JB _lbl_17f
	LONG $0xf0428d44	// leal -0x10(%rdx), %r8d	// LEAL -0x10(DX), R8
	WORD $0x8944; BYTE $0xc0	// movl %r8d, %eax	// MOVL R8, AX
	WORD $0xe8c1; BYTE $0x4	// shrl $4, %eax	// SHRL $0x4, AX
	WORD $0x588d; BYTE $0x1	// leal 1(%rax), %ebx	// LEAL 0x1(AX), BX
	WORD $0xc3f6; BYTE $0x3	// testb $3, %bl	// TESTB $0x3, BX
	WORD $0x2d74	// je 0x142	// JE _lbl_142
	LONG $0xc66ef9c5	// vmovd %esi, %xmm0	// VMOVD SI, X0
	LONG $0x7879e2c4; BYTE $0xc0	// vpbroadcastb %xmm0, %xmm0	// VPBROADCASTB X0, X0
	WORD $0x104	// addb $1, %al	// ADDB $0x1, AX
	WORD $0xb60f; BYTE $0xd8	// movzbl %al, %ebx	// 
	WORD $0xe383; BYTE $0x3	// andl $3, %ebx	// ANDL $0x3, BX
	LONG $0x4e3c148	// shlq $4, %rbx	// SHLQ $0x4, BX
	WORD $0xc031	// xorl %eax, %eax	// XORL AX, AX
	LONG $0x401f0f	// nopl (%rax)	// NOPL (AX)

_lbl_130:
	LONG $0x47ffac5; BYTE $0x1	// vmovdqu %xmm0, (%rcx, %rax)	// VMOVDQU X0, (CX)(AX*1)
	LONG $0x10c08348	// addq $0x10, %rax	// ADDQ $0x10, AX
	WORD $0xc339	// cmpl %eax, %ebx	// CMPL BX, AX
	WORD $0xf375	// jne 0x130	// JNE _lbl_130
	WORD $0xc229	// subl %eax, %edx	// SUBL AX, DX
	WORD $0x148; BYTE $0xc1	// addq %rax, %rcx	// ADDQ AX, CX

_lbl_142:
	LONG $0x30f88341	// cmpl $0x30, %r8d	// CMPL R8, $0x30
	WORD $0x3772	// jb 0x17f	// JB _lbl_17f
	LONG $0xc66ef9c5	// vmovd %esi, %xmm0	// VMOVD SI, X0
	LONG $0x7879e2c4; BYTE $0xc0	// vpbroadcastb %xmm0, %xmm0	// VPBROADCASTB X0, X0
	QUAD $0x841f0f2e66; WORD $0x0	// nopw %cs:(%rax, %rax)	// NOPW (CS)(AX*1)
	LONG $0x441f0f; BYTE $0x0	// nopl (%rax, %rax)	// NOPL (AX)(AX*1)

_lbl_160:
	LONG $0x17ffac5	// vmovdqu %xmm0, (%rcx)	// VMOVDQU X0, (CX)
	LONG $0x417ffac5; BYTE $0x10	// vmovdqu %xmm0, 0x10(%rcx)	// VMOVDQU X0, 0x10(CX)
	LONG $0x417ffac5; BYTE $0x20	// vmovdqu %xmm0, 0x20(%rcx)	// VMOVDQU X0, 0x20(CX)
	LONG $0x417ffac5; BYTE $0x30	// vmovdqu %xmm0, 0x30(%rcx)	// VMOVDQU X0, 0x30(CX)
	LONG $0x40c18348	// addq $0x40, %rcx	// ADDQ $0x40, CX
	WORD $0xc283; BYTE $0xc0	// addl $-0x40, %edx	// ADDL $-0x40, DX
	WORD $0xfa83; BYTE $0xf	// cmpl $0xf, %edx	// CMPL DX, $0xf
	WORD $0xe177	// ja 0x160	// JA _lbl_160

_lbl_17f:
	WORD $0xfa83; BYTE $0x8	// cmpl $8, %edx	// CMPL DX, $0x8
	LONG $0xa3820f; WORD $0x0	// jb 0x22b	// JB _lbl_22b
	WORD $0x428d; BYTE $0xf8	// leal -8(%rdx), %eax	// LEAL -0x8(DX), AX
	WORD $0x8a8	// testb $8, %al	// TESTB $0x8, AX
	WORD $0x2c75	// jne 0x1bb	// JNE _lbl_1bb
	WORD $0x8840; BYTE $0x31	// movb %sil, (%rcx)	// MOVB SI, (CX)
	LONG $0x1718840	// movb %sil, 1(%rcx)	// MOVB SI, 0x1(CX)
	LONG $0x2718840	// movb %sil, 2(%rcx)	// MOVB SI, 0x2(CX)
	LONG $0x3718840	// movb %sil, 3(%rcx)	// MOVB SI, 0x3(CX)
	LONG $0x4718840	// movb %sil, 4(%rcx)	// MOVB SI, 0x4(CX)
	LONG $0x5718840	// movb %sil, 5(%rcx)	// MOVB SI, 0x5(CX)
	LONG $0x6718840	// movb %sil, 6(%rcx)	// MOVB SI, 0x6(CX)
	LONG $0x7718840	// movb %sil, 7(%rcx)	// MOVB SI, 0x7(CX)
	LONG $0x8c18348	// addq $8, %rcx	// ADDQ $0x8, CX
	WORD $0xc289	// movl %eax, %edx	// MOVL AX, DX
	WORD $0xf883; BYTE $0x8	// cmpl $8, %eax	// CMPL AX, $0x8
	WORD $0x772	// jb 0x1c0	// JB _lbl_1c0
	WORD $0x25eb	// jmp 0x1e0	// JMP _lbl_1e0

_lbl_1bb:
	WORD $0xf883; BYTE $0x8	// cmpl $8, %eax	// CMPL AX, $0x8
	WORD $0x2073	// jae 0x1e0	// JAE _lbl_1e0

_lbl_1c0:
	WORD $0xf883; BYTE $0x4	// cmpl $4, %eax	// CMPL AX, $0x4
	WORD $0x6d72	// jb 0x232	// JB _lbl_232

_lbl_1c5:
	LONG $0xfc408d44	// leal -4(%rax), %r8d	// LEAL -0x4(AX), R8
	LONG $0xfcf88141; WORD $0x1; BYTE $0x0	// cmpl $0x1fc, %r8d	// CMPL R8, $0x1fc
	WORD $0x6873	// jae 0x23a	// JAE _lbl_23a
	WORD $0x8948; BYTE $0xcb	// movq %rcx, %rbx	// MOVQ CX, BX
	LONG $0x136e9; BYTE $0x0	// jmp 0x310	// JMP _lbl_310
	LONG $0x441f0f66; WORD $0x0	// nopw (%rax, %rax)	// NOPW (AX)(AX*1)

_lbl_1e0:
	WORD $0x8840; BYTE $0x31	// movb %sil, (%rcx)	// MOVB SI, (CX)
	LONG $0x1718840	// movb %sil, 1(%rcx)	// MOVB SI, 0x1(CX)
	LONG $0x2718840	// movb %sil, 2(%rcx)	// MOVB SI, 0x2(CX)
	LONG $0x3718840	// movb %sil, 3(%rcx)	// MOVB SI, 0x3(CX)
	LONG $0x4718840	// movb %sil, 4(%rcx)	// MOVB SI, 0x4(CX)
	LONG $0x5718840	// movb %sil, 5(%rcx)	// MOVB SI, 0x5(CX)
	LONG $0x6718840	// movb %sil, 6(%rcx)	// MOVB SI, 0x6(CX)
	LONG $0x7718840	// movb %sil, 7(%rcx)	// MOVB SI, 0x7(CX)
	LONG $0x8718840	// movb %sil, 8(%rcx)	// MOVB SI, 0x8(CX)
	LONG $0x9718840	// movb %sil, 9(%rcx)	// MOVB SI, 0x9(CX)
	LONG $0xa718840	// movb %sil, 0xa(%rcx)	// MOVB SI, 0xa(CX)
	LONG $0xb718840	// movb %sil, 0xb(%rcx)	// MOVB SI, 0xb(CX)
	LONG $0xc718840	// movb %sil, 0xc(%rcx)	// MOVB SI, 0xc(CX)
	LONG $0xd718840	// movb %sil, 0xd(%rcx)	// MOVB SI, 0xd(CX)
	LONG $0xe718840	// movb %sil, 0xe(%rcx)	// MOVB SI, 0xe(CX)
	LONG $0xf718840	// movb %sil, 0xf(%rcx)	// MOVB SI, 0xf(CX)
	LONG $0x10c18348	// addq $0x10, %rcx	// ADDQ $0x10, CX
	WORD $0xc283; BYTE $0xf0	// addl $-0x10, %edx	// ADDL $-0x10, DX
	WORD $0xfa83; BYTE $0x7	// cmpl $7, %edx	// CMPL DX, $0x7
	WORD $0xb577	// ja 0x1e0	// JA _lbl_1e0

_lbl_22b:
	WORD $0xd089	// movl %edx, %eax	// MOVL DX, AX
	WORD $0xf883; BYTE $0x4	// cmpl $4, %eax	// CMPL AX, $0x4
	WORD $0x9373	// jae 0x1c5	// JAE _lbl_1c5

_lbl_232:
	WORD $0x8948; BYTE $0xcb	// movq %rcx, %rbx	// MOVQ CX, BX
	LONG $0xf1e9; BYTE $0x0	// jmp 0x32b	// JMP _lbl_32b

_lbl_23a:
	LONG $0x2e8c141	// shrl $2, %r8d	// SHRL $0x2, R8
	LONG $0x1c08341	// addl $1, %r8d	// ADDL $0x1, R8
	WORD $0x8945; BYTE $0xc1	// movl %r8d, %r9d	// MOVL R8, R9
	LONG $0x80e18341	// andl $0xffffff80, %r9d	// ANDL $0xffffff80, R9
	QUAD $0x8d148d42	// leal (, %r9, 4), %edx	// LEAL (R9*4), DX
	WORD $0xd029	// subl %edx, %eax	// SUBL DX, AX
	LONG $0x891c8d4a	// leaq (%rcx, %r9, 4), %rbx	// LEAQ (CX)(R9*4), BX
	LONG $0xc66ef9c5	// vmovd %esi, %xmm0	// VMOVD SI, X0
	LONG $0x787de2c4; BYTE $0xc0	// vpbroadcastb %xmm0, %ymm0	// VPBROADCASTB X0, Y0
	WORD $0xd231	// xorl %edx, %edx	// XORL DX, DX
	QUAD $0x841f0f2e66; WORD $0x0	// nopw %cs:(%rax, %rax)	// NOPW (CS)(AX*1)
	LONG $0x401f0f	// nopl (%rax)	// NOPL (AX)

_lbl_270:
	LONG $0x47ffec5; BYTE $0x91	// vmovdqu %ymm0, (%rcx, %rdx, 4)	// VMOVDQU Y0, (CX)(DX*4)
	LONG $0x447ffec5; WORD $0x2091	// vmovdqu %ymm0, 0x20(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x20(CX)(DX*4)
	LONG $0x447ffec5; WORD $0x4091	// vmovdqu %ymm0, 0x40(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x40(CX)(DX*4)
	LONG $0x447ffec5; WORD $0x6091	// vmovdqu %ymm0, 0x60(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x60(CX)(DX*4)
	QUAD $0x8091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x80(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x80(CX)(DX*4)
	QUAD $0xa091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0xa0(%rcx, %rdx, 4)	// VMOVDQU Y0, 0xa0(CX)(DX*4)
	QUAD $0xc091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0xc0(%rcx, %rdx, 4)	// VMOVDQU Y0, 0xc0(CX)(DX*4)
	QUAD $0xe091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0xe0(%rcx, %rdx, 4)	// VMOVDQU Y0, 0xe0(CX)(DX*4)
	QUAD $0x10091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x100(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x100(CX)(DX*4)
	QUAD $0x12091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x120(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x120(CX)(DX*4)
	QUAD $0x14091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x140(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x140(CX)(DX*4)
	QUAD $0x16091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x160(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x160(CX)(DX*4)
	QUAD $0x18091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x180(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x180(CX)(DX*4)
	QUAD $0x1a091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x1a0(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x1a0(CX)(DX*4)
	QUAD $0x1c091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x1c0(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x1c0(CX)(DX*4)
	QUAD $0x1e091847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x1e0(%rcx, %rdx, 4)	// VMOVDQU Y0, 0x1e0(CX)(DX*4)
	LONG $0x80ea8348	// subq $-0x80, %rdx	// SUBQ $-0x80, DX
	WORD $0x3949; BYTE $0xd1	// cmpq %rdx, %r9	// CMPQ R9, DX
	LONG $0xff70850f; WORD $0xffff	// jne 0x270	// JNE _lbl_270
	WORD $0x394d; BYTE $0xc1	// cmpq %r8, %r9	// CMPQ R9, R8
	WORD $0x2674	// je 0x32b	// JE _lbl_32b
	QUAD $0x841f0f2e66; WORD $0x0	// nopw %cs:(%rax, %rax)	// NOPW (CS)(AX*1)
	BYTE $0x90	// nop	// NOP 

_lbl_310:
	WORD $0x8840; BYTE $0x33	// movb %sil, (%rbx)	// MOVB SI, (BX)
	LONG $0x1738840	// movb %sil, 1(%rbx)	// MOVB SI, 0x1(BX)
	LONG $0x2738840	// movb %sil, 2(%rbx)	// MOVB SI, 0x2(BX)
	LONG $0x3738840	// movb %sil, 3(%rbx)	// MOVB SI, 0x3(BX)
	LONG $0x4c38348	// addq $4, %rbx	// ADDQ $0x4, BX
	WORD $0xc083; BYTE $0xfc	// addl $-4, %eax	// ADDL $-0x4, AX
	WORD $0xf883; BYTE $0x3	// cmpl $3, %eax	// CMPL AX, $0x3
	WORD $0xe577	// ja 0x310	// JA _lbl_310

_lbl_32b:
	WORD $0xc085	// testl %eax, %eax	// TESTL AX, AX
	LONG $0x19c840f; WORD $0x0	// je 0x4cf	// JE _lbl_4cf
	LONG $0xff408d44	// leal -1(%rax), %r8d	// LEAL -0x1(AX), R8
	LONG $0xff88341	// cmpl $0xf, %r8d	// CMPL R8, $0xf
	WORD $0x873	// jae 0x345	// JAE _lbl_345

_lbl_33d:
	WORD $0x8948; BYTE $0xda	// movq %rbx, %rdx	// MOVQ BX, DX
	LONG $0x16ee9; BYTE $0x0	// jmp 0x4b3	// JMP _lbl_4b3

_lbl_345:
	QUAD $0x1ffffff80b949; WORD $0x0	// movabsq $0x1ffffff80, %r9	// 
	LONG $0x7ff88341	// cmpl $0x7f, %r8d	// CMPL R8, $0x7f
	WORD $0x773	// jae 0x35c	// JAE _lbl_35c
	WORD $0xc931	// xorl %ecx, %ecx	// XORL CX, CX
	LONG $0x123e9; BYTE $0x0	// jmp 0x47f	// JMP _lbl_47f

_lbl_35c:
	LONG $0x1508d4d	// leaq 1(%r8), %r10	// LEAQ 0x1(R8), R10
	WORD $0x894c; BYTE $0xd1	// movq %r10, %rcx	// MOVQ R10, CX
	WORD $0x214c; BYTE $0xc9	// andq %r9, %rcx	// ANDQ R9, CX
	LONG $0xc66ef9c5	// vmovd %esi, %xmm0	// VMOVD SI, X0
	LONG $0x787de2c4; BYTE $0xc0	// vpbroadcastb %xmm0, %ymm0	// VPBROADCASTB X0, Y0
	LONG $0x80518d48	// leaq -0x80(%rcx), %rdx	// LEAQ -0x80(CX), DX
	WORD $0x8949; BYTE $0xd6	// movq %rdx, %r14	// MOVQ DX, R14
	LONG $0x7eec149	// shrq $7, %r14	// SHRQ $0x7, R14
	LONG $0x1c68349	// addq $1, %r14	// ADDQ $0x1, R14
	WORD $0x8945; BYTE $0xf3	// movl %r14d, %r11d	// MOVL R14, R11
	LONG $0x3e38341	// andl $3, %r11d	// ANDL $0x3, R11
	LONG $0x80fa8148; WORD $0x1; BYTE $0x0	// cmpq $0x180, %rdx	// CMPQ DX, $0x180
	WORD $0x773	// jae 0x395	// JAE _lbl_395
	WORD $0xd231	// xorl %edx, %edx	// XORL DX, DX
	LONG $0x9fe9; BYTE $0x0	// jmp 0x434	// JMP _lbl_434

_lbl_395:
	LONG $0xfce68349	// andq $0xfffffffffffffffc, %r14	// ANDQ $-0x4, R14
	WORD $0xd231	// xorl %edx, %edx	// XORL DX, DX
	LONG $0x441f0f; BYTE $0x0	// nopl (%rax, %rax)	// NOPL (AX)(AX*1)

_lbl_3a0:
	LONG $0x47ffec5; BYTE $0x13	// vmovdqu %ymm0, (%rbx, %rdx)	// VMOVDQU Y0, (BX)(DX*1)
	LONG $0x447ffec5; WORD $0x2013	// vmovdqu %ymm0, 0x20(%rbx, %rdx)	// VMOVDQU Y0, 0x20(BX)(DX*1)
	LONG $0x447ffec5; WORD $0x4013	// vmovdqu %ymm0, 0x40(%rbx, %rdx)	// VMOVDQU Y0, 0x40(BX)(DX*1)
	LONG $0x447ffec5; WORD $0x6013	// vmovdqu %ymm0, 0x60(%rbx, %rdx)	// VMOVDQU Y0, 0x60(BX)(DX*1)
	QUAD $0x8013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x80(%rbx, %rdx)	// VMOVDQU Y0, 0x80(BX)(DX*1)
	QUAD $0xa013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0xa0(%rbx, %rdx)	// VMOVDQU Y0, 0xa0(BX)(DX*1)
	QUAD $0xc013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0xc0(%rbx, %rdx)	// VMOVDQU Y0, 0xc0(BX)(DX*1)
	QUAD $0xe013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0xe0(%rbx, %rdx)	// VMOVDQU Y0, 0xe0(BX)(DX*1)
	QUAD $0x10013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x100(%rbx, %rdx)	// VMOVDQU Y0, 0x100(BX)(DX*1)
	QUAD $0x12013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x120(%rbx, %rdx)	// VMOVDQU Y0, 0x120(BX)(DX*1)
	QUAD $0x14013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x140(%rbx, %rdx)	// VMOVDQU Y0, 0x140(BX)(DX*1)
	QUAD $0x16013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x160(%rbx, %rdx)	// VMOVDQU Y0, 0x160(BX)(DX*1)
	QUAD $0x18013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x180(%rbx, %rdx)	// VMOVDQU Y0, 0x180(BX)(DX*1)
	QUAD $0x1a013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x1a0(%rbx, %rdx)	// VMOVDQU Y0, 0x1a0(BX)(DX*1)
	QUAD $0x1c013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x1c0(%rbx, %rdx)	// VMOVDQU Y0, 0x1c0(BX)(DX*1)
	QUAD $0x1e013847ffec5; BYTE $0x0	// vmovdqu %ymm0, 0x1e0(%rbx, %rdx)	// VMOVDQU Y0, 0x1e0(BX)(DX*1)
	LONG $0xc28148; WORD $0x2; BYTE $0x0	// addq $0x200, %rdx	// ADDQ $0x200, DX
	LONG $0xfcc68349	// addq $-4, %r14	// ADDQ $-0x4, R14
	LONG $0xff6c850f; WORD $0xffff	// jne 0x3a0	// JNE _lbl_3a0

_lbl_434:
	WORD $0x854d; BYTE $0xdb	// testq %r11, %r11	// TESTQ R11, R11
	WORD $0x3b74	// je 0x474	// JE _lbl_474
	LONG $0x1a348d4c	// leaq (%rdx, %rbx), %r14	// LEAQ (DX)(BX*1), R14
	LONG $0x60c68349	// addq $0x60, %r14	// ADDQ $0x60, R14
	LONG $0x7e3c149	// shlq $7, %r11	// SHLQ $0x7, R11
	WORD $0xd231	// xorl %edx, %edx	// XORL DX, DX
	QUAD $0x841f0f66; BYTE $0x0	// nopw (%rax, %rax)	// NOPW (AX)(AX*1)

_lbl_450:
	LONG $0x7f7ec1c4; WORD $0x1644; BYTE $0xa0	// vmovdqu %ymm0, -0x60(%r14, %rdx)	// VMOVDQU Y0, -0x60(R14)(DX*1)
	LONG $0x7f7ec1c4; WORD $0x1644; BYTE $0xc0	// vmovdqu %ymm0, -0x40(%r14, %rdx)	// VMOVDQU Y0, -0x40(R14)(DX*1)
	LONG $0x7f7ec1c4; WORD $0x1644; BYTE $0xe0	// vmovdqu %ymm0, -0x20(%r14, %rdx)	// VMOVDQU Y0, -0x20(R14)(DX*1)
	LONG $0x7f7ec1c4; WORD $0x1604	// vmovdqu %ymm0, (%r14, %rdx)	// VMOVDQU Y0, (R14)(DX*1)
	LONG $0x80ea8348	// subq $-0x80, %rdx	// SUBQ $-0x80, DX
	WORD $0x3949; BYTE $0xd3	// cmpq %rdx, %r11	// CMPQ R11, DX
	WORD $0xdc75	// jne 0x450	// JNE _lbl_450

_lbl_474:
	WORD $0x3949; BYTE $0xca	// cmpq %rcx, %r10	// CMPQ R10, CX
	WORD $0x5674	// je 0x4cf	// JE _lbl_4cf
	LONG $0x70c2f641	// testb $0x70, %r10b	// TESTB $0x70, R10
	WORD $0x5b74	// je 0x4da	// JE _lbl_4da

_lbl_47f:
	LONG $0x1c08349	// addq $1, %r8	// ADDQ $0x1, R8
	LONG $0x70c18349	// addq $0x70, %r9	// ADDQ $0x70, R9
	WORD $0x214d; BYTE $0xc1	// andq %r8, %r9	// ANDQ R8, R9
	WORD $0x2944; BYTE $0xc8	// subl %r9d, %eax	// SUBL R9, AX
	LONG $0xb148d4a	// leaq (%rbx, %r9), %rdx	// LEAQ (BX)(R9*1), DX
	LONG $0xc66ef9c5	// vmovd %esi, %xmm0	// VMOVD SI, X0
	LONG $0x7879e2c4; BYTE $0xc0	// vpbroadcastb %xmm0, %xmm0	// VPBROADCASTB X0, X0
	LONG $0x441f0f66; WORD $0x0	// nopw (%rax, %rax)	// NOPW (AX)(AX*1)

_lbl_4a0:
	LONG $0x47ffac5; BYTE $0xb	// vmovdqu %xmm0, (%rbx, %rcx)	// VMOVDQU X0, (BX)(CX*1)
	LONG $0x10c18348	// addq $0x10, %rcx	// ADDQ $0x10, CX
	WORD $0x3949; BYTE $0xc9	// cmpq %rcx, %r9	// CMPQ R9, CX
	WORD $0xf275	// jne 0x4a0	// JNE _lbl_4a0
	WORD $0x394d; BYTE $0xc8	// cmpq %r9, %r8	// CMPQ R8, R9
	WORD $0x1c74	// je 0x4cf	// JE _lbl_4cf

_lbl_4b3:
	WORD $0xc083; BYTE $0x1	// addl $1, %eax	// ADDL $0x1, AX
	QUAD $0x841f0f2e66; WORD $0x0	// nopw %cs:(%rax, %rax)	// NOPW (CS)(AX*1)

_lbl_4c0:
	WORD $0x8840; BYTE $0x32	// movb %sil, (%rdx)	// MOVB SI, (DX)
	LONG $0x1c28348	// addq $1, %rdx	// ADDQ $0x1, DX
	WORD $0xc083; BYTE $0xff	// addl $-1, %eax	// ADDL $-0x1, AX
	WORD $0xf883; BYTE $0x1	// cmpl $1, %eax	// CMPL AX, $0x1
	WORD $0xf177	// ja 0x4c0	// JA _lbl_4c0

_lbl_4cf:
	WORD $0x478b; BYTE $0x8	// movl 8(%rdi), %eax	// MOVL 0x8(DI), AX

_lbl_4d2:
	BYTE $0x5b	// popq %rbx	// POPQ BX
	WORD $0x5e41	// popq %r14	// POPQ R14
	BYTE $0x5d	// popq %rbp	// POPQ BP
	WORD $0xf8c5; BYTE $0x77	// vzeroupper	// VZEROUPPER 
	BYTE $0xc3	// retq	// RET 

_lbl_4da:
	WORD $0x148; BYTE $0xcb	// addq %rcx, %rbx	// ADDQ CX, BX
	WORD $0xc829	// subl %ecx, %eax	// SUBL CX, AX
	LONG $0xfffe59e9; BYTE $0xff	// jmp 0x33d	// JMP _lbl_33d

// data size: 13
	QUAD $0x73656d2072756f79; LONG $0x65676173; BYTE $0x0




TEXT Â·subr(SB), NOSPLIT | NOFRAME, $0 - 8
	NO_LOCAL_POINTERS

_subr:
	CALL Â·__native_entry__+16(SB)
	MOVQ AX, ret+0(FP)
	RET


TEXT Â·subr2(SB), NOSPLIT | NOFRAME, $0 - 16
	NO_LOCAL_POINTERS

_subr2:
	MOVQ b+0(FP), DI
	CALL Â·__native_entry__+32(SB)
	MOVQ AX, ret+8(FP)
	RET


TEXT Â·subr3(SB), NOSPLIT | NOFRAME, $0 - 16
	NO_LOCAL_POINTERS

_subr3:
	MOVQ b+0(FP), DI
	CALL Â·__native_entry__+112(SB)
	MOVQ AX, ret+8(FP)
	RET


TEXT Â·subrSimd(SB), NOSPLIT | NOFRAME, $0 - 13
	NO_LOCAL_POINTERS

_subrSimd:
	MOVQ b+0(FP), DI
	MOVB v+8(FP), SI
	CALL Â·__native_entry__+208(SB)
	MOVL AX, ret+9(FP)
	RET



